{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d0030442",
   "metadata": {},
   "source": [
    "# Incendios forestales en Grecia"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41cb353f",
   "metadata": {
    "jupyter": {
     "source_hidden": false
    }
   },
   "source": [
    "\n",
    "En este ejemplo, recuperaremos los datos asociados a los [incendios forestales en Grecia en el 2023](https://es.wikipedia.org/wiki/Incendios_forestales_en_Grecia_de_2023) para comprender su evolución y extensión. Generaremos una serie temporal asociada a estos datos y dos visualizaciones del evento.\n",
    "\n",
    "En particular, analizaremos la zona que está alrededor de la ciudad de [Alexandroupolis](https://es.wikipedia.org/wiki/Alejandr%C3%B3polis), que se vio gravemente afectada por incendios forestales, con la consiguiente pérdida de vidas, propiedades y zonas boscosas.\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5875113a",
   "metadata": {},
   "source": [
    "## Esquema de las etapas del análisis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b09ac9d4",
   "metadata": {
    "jupyter": {
     "source_hidden": false
    }
   },
   "source": [
    "\n",
    "- Identificación de los parámetros de búsqueda\n",
    "  - AOI, ventana temporal\n",
    "  - _Endpoint_, proveedor, identificador del catálogo (\"nombre corto\")\n",
    "- Obtención de los resultados de la búsqueda\n",
    "  - Inspección, análisis para identificar características, bandas de interés\n",
    "  - Almacenamos los resultados en un DataFrame para facilitar la exploración\n",
    "- Exploración y refinamiento de los resultados de la búsqueda\n",
    "  - Identificar los gránulos de mayor valor\n",
    "  - Filtrar los gránulos extraños con una contribución mínima\n",
    "  - Integrar los gránulos filtrados en un DataFrame\n",
    "  - Identificar el tipo de resultado que se quiere generar\n",
    "- Procesamiento de los datos para generar resultados relevantes\n",
    "  - Descargar los gránulos relevantes en Xarray DataArray, apilados adecuadamente\n",
    "  - Llevar a cabo los cálculos intermedios necesarios\n",
    "  - Unir los fragmentos de datos relevantes en la visualización\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecfe29a9",
   "metadata": {},
   "source": [
    "### Importación preliminar\n",
    "\n",
    "```{code-cell} python jupyter={\"source_hidden\": false}\n",
    "from warnings import filterwarnings\n",
    "filterwarnings('ignore')\n",
    "import numpy as np, pandas as pd, xarray as xr\n",
    "import rioxarray as rio\n",
    "```\n",
    "\n",
    "```{code-cell} python jupyter={\"source_hidden\": false}\n",
    "# Imports for plotting\n",
    "import hvplot.pandas, hvplot.xarray\n",
    "import geoviews as gv\n",
    "from geoviews import opts\n",
    "gv.extension('bokeh')\n",
    "```\n",
    "\n",
    "```{code-cell} python jupyter={\"source_hidden\": false}\n",
    "# STAC imports to retrieve cloud data\n",
    "from pystac_client import Client\n",
    "from osgeo import gdal\n",
    "# GDAL setup for accessing cloud data\n",
    "gdal.SetConfigOption('GDAL_HTTP_COOKIEFILE','~/.cookies.txt')\n",
    "gdal.SetConfigOption('GDAL_HTTP_COOKIEJAR', '~/.cookies.txt')\n",
    "gdal.SetConfigOption('GDAL_DISABLE_READDIR_ON_OPEN','EMPTY_DIR')\n",
    "gdal.SetConfigOption('CPL_VSIL_CURL_ALLOWED_EXTENSIONS','TIF, TIFF')\n",
    "```\n",
    "\n",
    "### Funciones prácticas\n",
    "\n",
    "```{code-cell} python jupyter={\"source_hidden\": false}\n",
    "# simple utility to make a rectangle with given center of width dx & height dy\n",
    "def make_bbox(pt,dx,dy):\n",
    "    '''Returns bounding-box represented as tuple (x_lo, y_lo, x_hi, y_hi)\n",
    "    given inputs pt=(x, y), width & height dx & dy respectively,\n",
    "    where x_lo = x-dx/2, x_hi=x+dx/2, y_lo = y-dy/2, y_hi = y+dy/2.\n",
    "    '''\n",
    "    return tuple(coord+sgn*delta for sgn in (-1,+1) for coord,delta in zip(pt, (dx/2,dy/2)))\n",
    "```\n",
    "\n",
    "```{code-cell} python jupyter={\"source_hidden\": false}\n",
    "# simple utility to plot an AOI or bounding-box\n",
    "def plot_bbox(bbox):\n",
    "    '''Given bounding-box, returns GeoViews plot of Rectangle & Point at center\n",
    "    + bbox: bounding-box specified as (lon_min, lat_min, lon_max, lat_max)\n",
    "    Assume longitude-latitude coordinates.\n",
    "    '''\n",
    "    # These plot options are fixed but can be over-ridden\n",
    "    point_opts = opts.Points(size=12, alpha=0.25, color='blue')\n",
    "    rect_opts = opts.Rectangles(line_width=2, alpha=0.1, color='red')\n",
    "    lon_lat = (0.5*sum(bbox[::2]), 0.5*sum(bbox[1::2]))\n",
    "    return (gv.Points([lon_lat]) * gv.Rectangles([bbox])).opts(point_opts, rect_opts)\n",
    "```\n",
    "\n",
    "```{code-cell} python jupyter={\"source_hidden\": false}\n",
    "# utility to extract search results into a Pandas DataFrame\n",
    "def search_to_dataframe(search):\n",
    "    '''Constructs Pandas DataFrame from PySTAC Earthdata search results.\n",
    "    DataFrame columns are determined from search item properties and assets.\n",
    "    'asset': string identifying an Asset type associated with a granule\n",
    "    'href': data URL for file associated with the Asset in a given row.'''\n",
    "    granules = list(search.items())\n",
    "    assert granules, \"Error: empty list of search results\"\n",
    "    props = list({prop for g in granules for prop in g.properties.keys()})\n",
    "    tile_ids = map(lambda granule: granule.id.split('_')[3], granules)\n",
    "    rows = (([g.properties.get(k, None) for k in props] + [a, g.assets[a].href, t])\n",
    "                for g, t in zip(granules,tile_ids) for a in g.assets )\n",
    "    df = pd.concat(map(lambda x: pd.DataFrame(x, index=props+['asset','href', 'tile_id']).T, rows),\n",
    "                   axis=0, ignore_index=True)\n",
    "    assert len(df), \"Empty DataFrame\"\n",
    "    return df\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acf7c762",
   "metadata": {
    "jupyter": {
     "source_hidden": false
    }
   },
   "source": [
    "\n",
    "Estas funciones podrían incluirse en archivos modular para proyectos de investigación más evolucionados. Para fines didácticos, se incluyen en este cuaderno computacional.\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6780e9d8",
   "metadata": {},
   "source": [
    "## Identificación de los parámetros de búsqueda\n",
    "\n",
    "```{code-cell} python jupyter={\"source_hidden\": false}\n",
    "dadia_forest = (26.18, 41.08)\n",
    "AOI = make_bbox(dadia_forest, 0.1, 0.1)\n",
    "DATE_RANGE = '2023-08-01/2023-09-30'.split('/')\n",
    "```\n",
    "\n",
    "```{code-cell} python jupyter={\"source_hidden\": false}\n",
    "# Optionally plot the AOI\n",
    "basemap = gv.tile_sources.ESRI(width=500, height=500, padding=0.1, alpha=0.25)\n",
    "plot_bbox(AOI) * basemap\n",
    "```\n",
    "\n",
    "```{code-cell} python jupyter={\"source_hidden\": false}\n",
    "search_params = dict(bbox=AOI, datetime=DATE_RANGE)\n",
    "print(search_params)\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## Obtención de los resultados de búsqueda\n",
    "\n",
    "```{code-cell} python jupyter={\"source_hidden\": false}\n",
    "ENDPOINT = 'https://cmr.earthdata.nasa.gov/stac'\n",
    "PROVIDER = 'LPCLOUD'\n",
    "COLLECTIONS = [\"OPERA_L3_DIST-ALERT-HLS_V1_1\"]\n",
    "# Update the dictionary opts with list of collections to search\n",
    "search_params.update(collections=COLLECTIONS)\n",
    "print(search_params)\n",
    "```\n",
    "\n",
    "```{code-cell} python jupyter={\"source_hidden\": false}\n",
    "catalog = Client.open(f'{ENDPOINT}/{PROVIDER}/')\n",
    "search_results = catalog.search(**search_params)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cbc8a25",
   "metadata": {
    "jupyter": {
     "source_hidden": false
    }
   },
   "source": [
    "\n",
    "Como de costumbre, codificaremos el resultado de la búsqueda en un Pandas `DataFrame`, analizaremos los resultados, y haremos algunas transformaciones para limpiarlos.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb836fc9",
   "metadata": {},
   "source": [
    "```{code-cell} python jupyter={\"source_hidden\": false}\n",
    "%%time\n",
    "df = search_to_dataframe(search_results)\n",
    "df.head()\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3769a02",
   "metadata": {
    "jupyter": {
     "source_hidden": false
    }
   },
   "source": [
    "\n",
    "Limpiaremos el `DataFrame` `df` de las formas típicas:\n",
    "\n",
    "- convertiendo la columna `datetime` en `DatetimeIndex`,\n",
    "- eliminando columnas de tipo `datetime` extrañas,\n",
    "- renombrando la columna `eo:cloud_cover` como `cloud_cover`,\n",
    "- convirtiendo la columna `cloud_cover` en valores de punto flotante, y\n",
    "- convertiendo las columnas restantes en cadenas de caracteres, y\n",
    "- estableciendo la columna `datetime` como `Index`.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80e8661a",
   "metadata": {},
   "source": [
    "```{code-cell} python jupyter={\"source_hidden\": false}\n",
    "df = df.drop(['end_datetime', 'start_datetime'], axis=1)\n",
    "df.datetime = pd.DatetimeIndex(df.datetime)\n",
    "df = df.rename(columns={'eo:cloud_cover':'cloud_cover'})\n",
    "df['cloud_cover'] = df['cloud_cover'].astype(np.float16)\n",
    "for col in ['asset', 'href', 'tile_id']:\n",
    "    df[col] = df[col].astype(pd.StringDtype())\n",
    "df = df.set_index('datetime').sort_index()\n",
    "df.info()\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## Exploración y refinamiento de los resultados de la búsqueda"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "999d9fe4",
   "metadata": {
    "jupyter": {
     "source_hidden": false
    }
   },
   "source": [
    "\n",
    "Examinemos el `DataFrame` `df` para comprender mejor los resultados de la búsqueda. En primer lugar, veamos cuántos mosaicos geográficos diferentes aparecen en los resultados de la búsqueda.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5534255e",
   "metadata": {},
   "source": [
    "```{code-cell} python jupyter={\"source_hidden\": false}\n",
    "df.tile_id.value_counts() \n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79e2a7eb",
   "metadata": {
    "jupyter": {
     "source_hidden": false
    }
   },
   "source": [
    "\n",
    "Entonces, el AOI se encuentra estrictamente dentro de un único mosaico geográfico MGRS llamado `T35TMF`. Analicemos la columna `asset`.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a306736",
   "metadata": {},
   "source": [
    "```{code-cell} python jupyter={\"source_hidden\": false}\n",
    "df.asset.value_counts().sort_values(ascending=False)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd85c5bf",
   "metadata": {
    "jupyter": {
     "source_hidden": false
    }
   },
   "source": [
    "\n",
    "Algunos de los nombres de estos activos no son tan simples y ordenados como los que encontramos con los productos de datos DIST-ALERT. Sin embargo, podemos identificar fácilmente las subcadenas de caracteres útiles. En este caso, elegimos sólo las filas en las que la columna `asset` incluye `'VEG-DIST-STATUS'` como subcadena de caracteres.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7194a5bd",
   "metadata": {},
   "source": [
    "```{code-cell} python jupyter={\"source_hidden\": false}\n",
    "idx_veg_dist_status = df.asset.str.contains('VEG-DIST-STATUS')\n",
    "idx_veg_dist_status\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57068d73",
   "metadata": {
    "jupyter": {
     "source_hidden": false
    }
   },
   "source": [
    "\n",
    "Podemos utilizar esta `Series` booleana con el método de acceso `.loc` de Pandas para filtrar solo las filas que queremos (por ejemplo, las que se conectan a archivos de datos ráster que almacenan la banda `VEG-DIST-STATUS`). Posteriormente podemos eliminar la columna `asset` (que ya no es necesaria).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cb4dffa",
   "metadata": {},
   "source": [
    "```{code-cell} python jupyter={\"source_hidden\": false}\n",
    "veg_dist_status = df.loc[idx_veg_dist_status]\n",
    "veg_dist_status = veg_dist_status.drop('asset', axis=1)\n",
    "veg_dist_status\n",
    "```\n",
    "\n",
    "```{code-cell} python jupyter={\"source_hidden\": false}\n",
    "print(len(veg_dist_status))\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d84dbce",
   "metadata": {
    "jupyter": {
     "source_hidden": false
    }
   },
   "source": [
    "\n",
    "Observe que algunas de las filas tienen la misma fecha pero horas diferentes (lo cual corresponde a varias observaciones en el mismo día del calendario UTC). Podemos agregar las URL en listas _remuestreando_ la serie temporal por día. Posteriormente podremos visualizar el resultado.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aabf2821",
   "metadata": {},
   "source": [
    "```{code-cell} python jupyter={\"source_hidden\": false}\n",
    "by_day = veg_dist_status.resample('1d').href.apply(list)\n",
    "display(by_day)\n",
    "by_day.map(len).hvplot.scatter(grid=True).opts(title='# of observations')\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77c83896",
   "metadata": {
    "jupyter": {
     "source_hidden": false
    }
   },
   "source": [
    "\n",
    "Limpiemos la `Series` `by_day` filtrando las filas que tienen listas vacías (es decir, fechas en las que no se adquirieron datos).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e753ac6",
   "metadata": {},
   "source": [
    "```{code-cell} python jupyter={\"source_hidden\": false}\n",
    "by_day = by_day.loc[by_day.map(bool)]\n",
    "by_day.map(len).hvplot.scatter(ylim=(0,2.1), grid=True).opts(title=\"# of observations\")\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8d4ba07",
   "metadata": {
    "jupyter": {
     "source_hidden": false
    }
   },
   "source": [
    "\n",
    "Ahora podemos utilizar la serie `by_day` remuestreada para extraer datos ráster para su análisis.\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3e895a7",
   "metadata": {},
   "source": [
    "## Procesamiento de los datos"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9ba46da",
   "metadata": {
    "jupyter": {
     "source_hidden": false
    }
   },
   "source": [
    "\n",
    "El incendio forestal cerca de Alexandroupolis comenzó alrededor del 21 de agosto y se propagó rápidamente, afectando en particular al cercano bosque de Dadia. En primer lugar, vamos a ensamblar un \"cubo de datos\" (por ejemplo, un arreglo apilado de rásters) a partir de los archivos remotos indexados en la serie Pandas `by_day`. Empezaremos seleccionando y cargando uno de los archivos GeoTIFF remotos para extraer los metadatos que se aplican a todos los rásteres asociados con este evento y este mosaico MGRS.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a9f2e4b",
   "metadata": {},
   "source": [
    "```{code-cell} python jupyter={\"source_hidden\": false}\n",
    "href = by_day[0][0]\n",
    "data = rio.open_rasterio(href).rename(dict(x='longitude', y='latitude'))\n",
    "crs = data.rio.crs\n",
    "shape = data.shape\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5264cd71",
   "metadata": {
    "jupyter": {
     "source_hidden": false
    }
   },
   "source": [
    "\n",
    "Antes de construir un `DataArray` apilado dentro de un bucle, definiremos un diccionario de Python llamado `template` que se utilizará para instanciar los cortes del arreglo. El diccionario `template` almacenará los metadatos extraídos del archivo GeoTIFF, especialmente las coordenadas.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "758f954a",
   "metadata": {},
   "source": [
    "```{code-cell} python jupyter={\"source_hidden\": false}\n",
    "template = dict()\n",
    "template['coords'] = data.coords.copy()\n",
    "del template['coords']['band']\n",
    "template['coords'].update({'time': by_day.index.values})\n",
    "template['dims'] = ['time', 'longitude', 'latitude']\n",
    "template['attrs'] = dict(description=f\"OPERA DSWX: VEG-DIST-STATUS\", units=None)\n",
    "\n",
    "print(template)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b471cc1",
   "metadata": {
    "jupyter": {
     "source_hidden": false
    }
   },
   "source": [
    "\n",
    "Utilizaremos un bucle para construir un arreglo apilado de rásteres a partir de la serie Pandas `by_day` (cuyas entradas son listas de cadenas de caracteres, es decir, URIs). Si la lista tiene un único elemento, la URL se puede leer directamente utilizando `rasterio.open`; de lo contrario, la función [`rasterio.merge.merge`](https://rasterio.readthedocs.io/en/latest/api/rasterio.merge.html) combina varios archivos de datos ráster adquiridos el mismo día en una única imagen ráster.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2bf7790",
   "metadata": {},
   "source": [
    "```{code-cell} python jupyter={\"source_hidden\": false}\n",
    "import rasterio\n",
    "from rasterio.merge import merge\n",
    "```\n",
    "\n",
    "```{code-cell} python jupyter={\"source_hidden\": false}\n",
    "%%time\n",
    "rasters = []\n",
    "for date, hrefs in by_day.items():\n",
    "    n_files = len(hrefs)\n",
    "    if n_files > 1:\n",
    "        print(f\"Merging {n_files} files for {date.strftime('%Y-%m-%d')}...\")\n",
    "        raster, _ = merge(hrefs)\n",
    "    else:\n",
    "        print(f\"Opening {n_files} file  for {date.strftime('%Y-%m-%d')}...\")\n",
    "        with rasterio.open(hrefs[0]) as ds:\n",
    "            raster = ds.read()\n",
    "    rasters.append(np.reshape(raster, newshape=shape))\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdf73d50",
   "metadata": {
    "jupyter": {
     "source_hidden": false
    }
   },
   "source": [
    "\n",
    "Los datos acumulados en la lista de `rasters` se almacenan como arreglos de NumPy. Así, en vez de llamar a `xarray.concat`, realizamos una llamada a `numpy.concatenate` dentro de una llamada al constructor `xarray.DataArray`. Vinculamos el objeto creado al identificador `stack`, asegurándonos de incluir también la información CRS.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef91f7f5",
   "metadata": {},
   "source": [
    "```{code-cell} python jupyter={\"source_hidden\": false}\n",
    "stack = xr.DataArray(data=np.concatenate(rasters, axis=0), **template)\n",
    "stack.rio.write_crs(crs, inplace=True)\n",
    "stack\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae9ff0fb",
   "metadata": {
    "jupyter": {
     "source_hidden": false
    }
   },
   "source": [
    "\n",
    "La pila `DataArray` `stack` tiene `time`, `longitude` y `latitude` como principales dimensiones de coordenadas. Podemos utilizarla para hacer algunos cálculos y generar visualizaciones.\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffbf80b4",
   "metadata": {},
   "source": [
    "### Visualización del área dañada"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9cdb89c",
   "metadata": {
    "jupyter": {
     "source_hidden": false
    }
   },
   "source": [
    "\n",
    "Para empezar, utilicemos los datos en `stack` para calcular la superficie total dañada. Los datos en `stack` provienen de la banda `VEG-DIST-STATUS` del producto DIST-ALERT. Interpretamos los valores de los píxeles en esta banda de la siguiente manera:\n",
    "\n",
    "- **0:** Sin alteración\n",
    "- **1:** La primera detección de alteraciones con cambio en la cobertura vegetal $<50\\%$\n",
    "- **2:** Detección provisional de alteraciones con cambio en la cobertura vegetal $<50\\%$\n",
    "- **3:** Detección confirmada de alteraciones con cambio en la cobertura vegetal $<50\\%$\n",
    "- **4:** La primera detección de alteraciones con cambio en la cobertura vegetal $\\ge50\\%$\n",
    "- **5:** Detección provisional de alteraciones con cambio en la cobertura vegetal $\\ge50\\%$\n",
    "- **6:** Detección confirmada de alteraciones con cambio en la cobertura vegetal $\\ge50\\%$\n",
    "- **7:** Detección finalizada de alteraciones con cambio en la cobertura vegetal $<50\\%$\n",
    "- **8:** Detección finalizada de alteraciones con cambio en la cobertura vegetal $\\ge50\\%$\n",
    "\n",
    "El valor del píxel particular que queremos marcar es 6, es decir, un píxel en el que se confirmó que por lo menos el 50% de la cubierta vegetal está dañada y en el que la alteración continúa activamente. Podemos utilizar el método `.sum` para sumar todos los píxeles con valor `6` y el método `.to_series` para representar la suma como una serie de Pandas indexada en el tiempo. También definimos `conversion_factor` que toma en cuenta el área de cada píxel en $\\mathrm{km}^2$ (recordemos que cada píxel tiene un área de $30\\mathrm{m}\\times30\\mathrm{m}$).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06a98929",
   "metadata": {},
   "source": [
    "```{code-cell} python jupyter={\"source_hidden\": false}\n",
    "pixel_val = 6\n",
    "conversion_factor = (30/1_000)**2 / pixel_val\n",
    "damage_area = stack.where(stack==pixel_val, other=0).sum(axis=(1,2)) \n",
    "damage_area = damage_area.to_series() * conversion_factor\n",
    "damage_area\n",
    "```\n",
    "\n",
    "```{code-cell} python jupyter={\"source_hidden\": false}\n",
    "plot_title = 'Damaged Area (km²)'\n",
    "line_plot_opts = dict(title=plot_title, grid=True, color='r')\n",
    "damage_area.hvplot.line(**line_plot_opts)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe403d06",
   "metadata": {
    "jupyter": {
     "source_hidden": false
    }
   },
   "source": [
    "\n",
    "Observando el gráfico anterior, parece que los incendios forestales comenzaron alrededor del 21 de agosto y se propagaron rápidamente.\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e30a9a7d",
   "metadata": {},
   "source": [
    "### Visualización de fragmentos temporales seleccionados"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61351a15",
   "metadata": {
    "jupyter": {
     "source_hidden": false
    }
   },
   "source": [
    "\n",
    "El bosque cercano de Dadia se vio especialmente afectado por los incendios. Para comprobarlo, trazaremos los datos ráster para ver la distribución espacial de los píxeles dañados en tres fechas concretas: 2 de agosto, 26 de agosto y 18 de septiembre. Una vez más, resaltaremos solamente los píxeles que tengan valor 6 en los datos ráster. Podemos extraer fácilmente esas fechas específicas de la serie temporal `by_day` utilizando una lista de fechas (por ejemplo, `dates_of_interest` en la siguiente celda).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3be471d3",
   "metadata": {},
   "source": [
    "```{code-cell} python jupyter={\"source_hidden\": false}\n",
    "dates_of_interest = ['2023-08-01', '2023-08-26', '2023-09-18']\n",
    "print(dates_of_interest)\n",
    "snapshots = stack.sel(time=dates_of_interest)\n",
    "snapshots\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14354e73",
   "metadata": {
    "jupyter": {
     "source_hidden": false
    }
   },
   "source": [
    "\n",
    "Vamos a hacer una secuencia estática de los gráficos. Empezaremos definiendo algunas opciones estándar almacenadas en diccionarios.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8359e994",
   "metadata": {},
   "source": [
    "```{code-cell} python jupyter={\"source_hidden\": false}\n",
    "image_opts = dict(\n",
    "                    x='longitude', \n",
    "                    y='latitude',\n",
    "                    rasterize=True, \n",
    "                    dynamic=True,\n",
    "                    crs=crs,\n",
    "                    shared_axes=False,\n",
    "                    colorbar=False,\n",
    "                    aspect='equal',\n",
    "                 )\n",
    "layout_opts = dict(xlabel='Longitude', ylabel=\"Latitude\")\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f523ca97",
   "metadata": {
    "jupyter": {
     "source_hidden": false
    }
   },
   "source": [
    "\n",
    "Construiremos un mapa de colores utilizando un diccionario de valores RGBA (por ejemplo, tuplas con tres entradas enteras entre 0 y 255, y una cuarta entrada de punto flotante entre 0.0 y 1.0 para la transparencia).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b67195ba",
   "metadata": {},
   "source": [
    "```{code-cell} python jupyter={\"source_hidden\": false}\n",
    "COLORS = { k:(0,0,0,0.0) for k in range(256) }\n",
    "COLORS.update({6: (255,0,0,1.0)})\n",
    "image_opts.update(cmap=list(COLORS.values()))\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15af5de7",
   "metadata": {
    "jupyter": {
     "source_hidden": false
    }
   },
   "source": [
    "\n",
    "Como siempre, empezaremos por cortar imágenes más pequeñas para asegurarnos de que\n",
    "`hvplot.image` funciona correctamente. Podemos reducir el valor del parámetro `steps` a `1` o `None` para obtener las imágenes renderizadas en resolución completa.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e51c819",
   "metadata": {},
   "source": [
    "```{code-cell} python jupyter={\"source_hidden\": false}\n",
    "steps = 100\n",
    "subset = slice(0,None, steps)\n",
    "view = snapshots.isel(longitude=subset, latitude=subset)\n",
    "(view.hvplot.image(**image_opts).opts(**layout_opts) * basemap).layout()\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7a3f66e",
   "metadata": {
    "jupyter": {
     "source_hidden": false
    }
   },
   "source": [
    "\n",
    "Si eliminamos la llamada a `.layout`, podemos producir un desplazamiento interactivo que muestre el progreso del incendio forestal utilizando todos los rásteres en `stack`.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "080ea68e",
   "metadata": {},
   "source": [
    "```{code-cell} python jupyter={\"source_hidden\": false}\n",
    "steps = 100\n",
    "subset = slice(0,None, steps)\n",
    "view = stack.isel(longitude=subset, latitude=subset,)\n",
    "(view.hvplot.image(**image_opts).opts(**layout_opts) * basemap)\n",
    "```\n",
    "\n",
    "---"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
